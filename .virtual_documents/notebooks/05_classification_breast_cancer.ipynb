


import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.datasets import load_breast_cancer
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.preprocessing import StandardScaler
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn.svm import SVC
from sklearn.ensemble import RandomForestClassifier
from sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc
import os

os.makedirs('../results', exist_ok=True)
os.makedirs('../data', exist_ok=True)
%matplotlib inline
plt.style.use('seaborn-v0_8')


# Chargement du dataset
data = load_breast_cancer(as_frame=True)
df = data.frame
df['target'] = data.target  # 0 = malignant, 1 = benign
print(f"Shape: {df.shape}")
df.head()


X = df.drop('target', axis=1)
y = df['target']

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)

scaler = StandardScaler()
X_train_scaled = scaler.fit_transform(X_train)
X_test_scaled = scaler.transform(X_test)

# Sauvegarde
df.to_csv('../data/breast_cancer_processed.csv', index=False)






models = {
    'Logistic Regression': LogisticRegression(random_state=42),
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'SVM': SVC(probability=True, random_state=42),
    'Random Forest': RandomForestClassifier(n_estimators=200, random_state=42)
}

results = []
best_model = None
best_acc = 0

for name, model in models.items():
    model.fit(X_train_scaled if 'Forest' not in name else X_train, y_train)
    y_pred = model.predict(X_test_scaled if 'Forest' not in name else X_test)
    acc = (y_pred == y_test).mean()
    if acc > best_acc:
        best_acc = acc
        best_model = model
        best_name = name
    results.append({'Model': name, 'Accuracy': round(acc, 4)})

pd.DataFrame(results)





param_grid = {'n_estimators': [200, 300], 'max_depth': [None, 10]}
rf = RandomForestClassifier(random_state=42)
grid = GridSearchCV(rf, param_grid, cv=5, scoring='accuracy')
grid.fit(X_train, y_train)

final_model = grid.best_estimator_
y_pred = final_model.predict(X_test)
print(f"Best params: {grid.best_params_}")
print(f"Final Accuracy: {(y_pred == y_test).mean():.4f}")





plt.figure(figsize=(15,5))

plt.subplot(1,3,1)
cm = confusion_matrix(y_test, y_pred)
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues')
plt.title('Confusion Matrix')
plt.ylabel('Vrai')
plt.xlabel('Pr√©dit')

plt.subplot(1,3,2)
fpr, tpr, _ = roc_curve(y_test, final_model.predict_proba(X_test)[:,1])
plt.plot(fpr, tpr, label=f'ROC AUC = {auc(fpr,tpr):.3f}')
plt.plot([0,1],[0,1],'r--')
plt.title('ROC Curve')
plt.legend()

plt.subplot(1,3,3)
feat_imp = pd.Series(final_model.feature_importances_, index=X.columns).sort_values(ascending=False)[:10]
sns.barplot(x=feat_imp.values, y=feat_imp.index, palette='viridis')
plt.title('Top 10 Feature Importance')

plt.tight_layout()
plt.savefig('../results/confusion_matrix.png', dpi=300, bbox_inches='tight')
plt.savefig('../results/roc_curves.png', dpi=300, bbox_inches='tight')
plt.savefig('../results/feature_importance_clf.png', dpi=300, bbox_inches='tight')
plt.show()



